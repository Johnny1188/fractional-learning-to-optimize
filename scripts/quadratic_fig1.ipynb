{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lovely_tensors as lt # can be removed\n",
    "import numpy as np\n",
    "import dill\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from fl2o.optimizee import MLPOptee, CustomParams\n",
    "from fl2o.optimizee_modules import MetaParameter\n",
    "from fl2o.optimizer import GD, Adam, FGD, AFOGD, CFGD, CFGD_ClosedForm, L2O_Update\n",
    "from fl2o.l2o import L2O\n",
    "from fl2o.data import MNIST, CustomTask, generate_least_squares_task, H1, H2, H3\n",
    "from fl2o.training import do_fit, find_best_lr, meta_train, get_optimal_lr, n_step_lookahead_lr_search_hfunc_tanh_twolayer_optee\n",
    "from fl2o.utils import dict_to_str, plot_log, plotter, plot_metrics, apply_publication_plt_settings, plot_strategy\n",
    "\n",
    "lt.monkey_patch() # can be removed\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "CKPT_PATH = os.getenv(\"CKPT_PATH\")\n",
    "DEVICE = os.getenv(\"DEVICE\", \"cpu\")\n",
    "\n",
    "print(f\"{DATA_PATH=}\\n{CKPT_PATH=}\\n{DEVICE=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load previous checkpoint (and skip meta-training of a new l2O optimizer)\n",
    "ckpt = torch.load(\n",
    "    os.path.join(\n",
    "        CKPT_PATH,\n",
    "        \"l2o\",\n",
    "        \"31-05_10-21__L2O__CFGD\",\n",
    "        \"ckpt_1000.pt\"\n",
    "        # \"meta_training\",\n",
    "        # \"20.pt\",\n",
    "    ),\n",
    "    map_location=torch.device(DEVICE),\n",
    "    pickle_module=dill,\n",
    ")\n",
    "l2o_dict = ckpt[\"l2o_dict\"]\n",
    "l2o_dict_best = ckpt[\"l2o_dict_best\"]\n",
    "l2o_dict_best[\"best_l2o_dict\"][\"opter\"].device = DEVICE\n",
    "l2o_dict[\"opter\"].device = DEVICE\n",
    "log = ckpt[\"log\"]\n",
    "config = ckpt[\"config\"]\n",
    "config[\"device\"] = DEVICE\n",
    "print(json.dumps(config, indent=4, default=str))\n",
    "\n",
    "### l2o\n",
    "# ckpt_2 = torch.load(\n",
    "#     os.path.join(\n",
    "#         CKPT_PATH,\n",
    "#         \"l2o\",\n",
    "#         \"02-02_11-34__L2O__L2O_Update\",\n",
    "#         \"ckpt.pt\"\n",
    "#         # \"meta_training\",\n",
    "#         # \"20.pt\",\n",
    "#     ),\n",
    "#     map_location=torch.device(DEVICE),\n",
    "#     pickle_module=dill,\n",
    "# )\n",
    "# l2o_dict_2 = ckpt_2[\"l2o_dict\"]\n",
    "# l2o_dict_best_2 = ckpt_2[\"l2o_dict_best\"]\n",
    "# log_2 = ckpt_2[\"log\"]\n",
    "# config_2 = ckpt_2[\"config\"]\n",
    "# print(json.dumps(config_2, indent=4, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Objective Function (Figure 1)\n",
    "$$\n",
    "\\min_x f(x, y) = 10 \\cdot x^2 + y^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quadratic objective function\n",
    "    min_x f(x, y) = 10 * x^2 + y^2\n",
    "\"\"\"\n",
    "def task_gen(device=\"cpu\"):\n",
    "    ### Least squares problem 1/2 x^T A x + b^T x\n",
    "    A = torch.tensor([[10., 0.], [0., 1.]], device=device)\n",
    "    b = torch.tensor([[0., 0.]], device=device).T\n",
    "    x_solution = torch.tensor([0., 0.], device=device)\n",
    "\n",
    "    loss_fn = lambda y_hat: 0.5 * y_hat @ A @ y_hat.T + b.T @ y_hat.T\n",
    "\n",
    "    return {\n",
    "        \"A\": A,\n",
    "        \"b\": b,\n",
    "        \"loss_fn\": loss_fn,\n",
    "        \"x_solution\": x_solution,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"optee\": {\n",
    "        \"optee_cls\": CustomParams,\n",
    "        \"optee_config\": {\n",
    "            \"dim\": (1, 2),\n",
    "            \"init_params\": torch.tensor([[1., -10.]], device=DEVICE),\n",
    "            \"param_func\": None,\n",
    "        },\n",
    "    },\n",
    "    \"opter\": {\n",
    "        \"opter_cls\": CFGD_ClosedForm,\n",
    "        \"opter_config\": {\n",
    "            \"lr\": get_optimal_lr,\n",
    "            \"gamma\": -1.,\n",
    "            \"c\": None,\n",
    "            \"version\": \"AT\",\n",
    "            \"init_points\": [torch.tensor([-1., -1.], device=DEVICE)],\n",
    "            \"device\": DEVICE,\n",
    "        },\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_cls\": CustomTask,\n",
    "        \"data_config\": {\n",
    "            \"task\": task_gen,\n",
    "            \"task_config\": {\n",
    "                # \"verbose\": False,\n",
    "                \"device\": DEVICE,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"n_iters\": 50,\n",
    "    \"l2o_dict\": None,\n",
    "    \"additional_metrics\": {\n",
    "        \"l2_dist(x*, x)\": lambda task, optee, **kwargs: \\\n",
    "            torch.norm(task[\"x_solution\"] - optee.params.detach(), p=2).item(),\n",
    "    },\n",
    "    \"device\": DEVICE,\n",
    "    \"seed\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### runs config\n",
    "runs = dict()\n",
    "\n",
    "runs[\"GD\"] = {\n",
    "    \"update_config\": {\n",
    "        \"opter\": {\n",
    "            \"opter_cls\": GD,\n",
    "            \"opter_config\": {\n",
    "                \"lr\": get_optimal_lr,\n",
    "                \"device\": DEVICE,\n",
    "            },\n",
    "        },\n",
    "        \"additional_metrics\": {\n",
    "            \"l2_dist(x*, x)\": lambda task, optee, **kwargs: \\\n",
    "                torch.norm(task[\"x_solution\"] - optee.params.detach(), p=2).item(),\n",
    "            \"x\": lambda optee, **kwargs: optee.params.detach().cpu().numpy(),\n",
    "        },\n",
    "    },\n",
    "    \"plot_config\": {\n",
    "        \"color\": \"black\",\n",
    "        \"linestyle\": \"dashed\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# for gamma in [-1., 0.01, 0.05, 0.25, 0.5, 1., 10.]:\n",
    "for gamma in [0.05]:\n",
    "    runs[r\"CFGD_ClosedForm, $\\gamma$=\" + str(gamma)] = {\n",
    "        \"update_config\": {\n",
    "            \"opter\": {\n",
    "                \"opter_cls\": CFGD_ClosedForm,\n",
    "                \"opter_config\": {\n",
    "                    \"lr\": get_optimal_lr,\n",
    "                    \"gamma\": gamma,\n",
    "                    \"c\": None,\n",
    "                    \"version\": \"AT\",\n",
    "                    \"init_points\": [torch.tensor([-1., -1.], device=DEVICE)],\n",
    "                    \"device\": DEVICE,\n",
    "                },\n",
    "            },\n",
    "            \"additional_metrics\": {\n",
    "                \"l2_dist(x*, x)\": lambda task, optee, **kwargs: \\\n",
    "                    torch.norm(task[\"x_solution\"] - optee.params.detach(), p=2).item(),\n",
    "                \"x\": lambda optee, **kwargs: optee.params.detach().cpu().numpy(),\n",
    "            },\n",
    "        },\n",
    "        # \"plot_config\": {\n",
    "        #     \"linestyle\": \"dashed\",\n",
    "        # },\n",
    "    }\n",
    "\n",
    "runs[\"L2O-CFGD\"] = {\n",
    "    \"update_config\": {\n",
    "        \"opter\": {\n",
    "            \"opter_cls\": L2O,\n",
    "            \"opter_config\": {\n",
    "                \"in_dim\": 3, # len(in_features) + 1\n",
    "                \"out_dim\": 3,\n",
    "                \"hidden_sz\": 40,\n",
    "                \"in_features\": (\"grad\", \"iter_num_enc\"),\n",
    "                \"base_opter_cls\": CFGD_ClosedForm,\n",
    "                \"base_opter_config\": {\n",
    "                    \"lr\": get_optimal_lr,\n",
    "                    \"gamma\": None,\n",
    "                    \"c\": None,\n",
    "                    \"version\": \"NA\",\n",
    "                    # \"init_points\": [torch.randn(1, config[\"data\"][\"d\"], requires_grad=False, device=DEVICE)],\n",
    "                    \"device\": DEVICE,\n",
    "                },\n",
    "                \"params_to_optimize\": {\n",
    "                    # \"gamma\": {\n",
    "                    #     \"idx\": 0,\n",
    "                    #     \"act_fns\": (\"identity\", \"diag\"),\n",
    "                    # },\n",
    "                    # \"gamma\": {\n",
    "                    #     \"idx\": 0,\n",
    "                    #     \"act_fns\": (\"alpha_to_gamma\", \"diag\"),\n",
    "                    #     \"beta\": 0.,\n",
    "                    # },\n",
    "                    \"gamma\": {\n",
    "                        \"idx\": (0, 1),\n",
    "                        \"act_fns\": (\"alpha_beta_to_gamma\", \"diag\"),\n",
    "                    },\n",
    "                    \"c\": {\n",
    "                        \"idx\": 2,\n",
    "                        \"act_fns\": (\"identity\",),\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"additional_metrics\": {\n",
    "            # \"gamma\": lambda opter, **kwargs: \\\n",
    "            #     # opter.base_opter.param_groups[0][\"gamma\"].item() \\\n",
    "            #     opter.base_opter.param_groups[0][\"gamma\"].detach().cpu().numpy() \\\n",
    "            #     if hasattr(opter, \"base_opter\") else opter.param_groups[0].get(\"gamma\", None),\n",
    "            # \"c\": lambda opter, **kwargs: \\\n",
    "            #     # opter.base_opter.param_groups[0][\"c\"].item() \\\n",
    "            #     opter.base_opter.param_groups[0][\"c\"].detach().cpu().numpy() \\\n",
    "            #     if hasattr(opter, \"base_opter\") else opter.param_groups[0].get(\"c\", None),\n",
    "            # \"alpha\": lambda opter, **kwargs: \\\n",
    "            #     # opter.base_opter.param_groups[0][\"gamma\"].item() \\\n",
    "            #     opter.base_opter.param_groups[0][\"alpha\"] \\\n",
    "            #     if hasattr(opter, \"base_opter\") else opter.param_groups[0].get(\"alpha\", None),\n",
    "            # \"beta\": lambda opter, **kwargs: \\\n",
    "            #     # opter.base_opter.param_groups[0][\"c\"].item() \\\n",
    "            #     opter.base_opter.param_groups[0][\"beta\"] \\\n",
    "            #     if hasattr(opter, \"base_opter\") else opter.param_groups[0].get(\"beta\", None),\n",
    "            # \"grad\": lambda opter, **kwargs: \\\n",
    "            #     opter.base_opter.state[0][\"last_grad\"].detach().cpu().numpy() \\\n",
    "            #     if hasattr(opter, \"base_opter\") else opter.state[0][\"last_grad\"].detach().cpu().numpy(),\n",
    "            \"x\": lambda optee, **kwargs: optee.params.detach().cpu().numpy(),\n",
    "            \"cos_sim(d, x.grad)\": lambda opter, **kwargs: \\\n",
    "                torch.cosine_similarity(\n",
    "                    opter.base_opter.state[0][\"last_update\"].flatten(),\n",
    "                    opter.base_opter.state[0][\"last_grad\"].flatten(),\n",
    "                    dim=0\n",
    "                ).item(),\n",
    "            \"last_lr\": lambda opter, **kwargs: \\\n",
    "                opter.base_opter.state[0][\"last_lr\"].item() if type(opter.base_opter.state[0][\"last_lr\"]) == torch.Tensor else opter.base_opter.state[0][\"last_lr\"],\n",
    "        },\n",
    "        # \"l2o_dict\": l2o_dict,\n",
    "        \"l2o_dict\": l2o_dict_best[\"best_l2o_dict\"],\n",
    "    },\n",
    "    \"plot_config\": {\n",
    "        # \"color\": \"orange\",\n",
    "        # \"color\": c_palette[3],\n",
    "        # \"linewidth\": 1.5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run all\n",
    "for run_name in runs.keys():\n",
    "    if \"log\" in runs[run_name]:\n",
    "        continue # already run\n",
    "    run_config = copy.deepcopy(config)\n",
    "    if \"update_config\" in runs[run_name] and runs[run_name][\"update_config\"] is not None:\n",
    "        run_config.update(runs[run_name][\"update_config\"])\n",
    "    print(f\"{run_name}:\")\n",
    "    \n",
    "    torch.manual_seed(config[\"seed\"])\n",
    "    np.random.seed(config[\"seed\"])\n",
    "\n",
    "    if \"lr\" in run_config[\"opter\"][\"opter_config\"] \\\n",
    "        and run_config[\"opter\"][\"opter_config\"][\"lr\"] == find_best_lr:\n",
    "        print(\"  > Finding best lr...\")\n",
    "        run_config[\"opter\"][\"opter_config\"][\"lr\"] = find_best_lr(\n",
    "            opter_cls=run_config[\"opter\"][\"opter_cls\"],\n",
    "            opter_config=run_config[\"opter\"][\"opter_config\"],\n",
    "            optee_cls=run_config[\"optee\"][\"optee_cls\"],\n",
    "            optee_config=run_config[\"optee\"][\"optee_config\"],\n",
    "            data_cls=run_config[\"data\"][\"data_cls\"],\n",
    "            data_config=run_config[\"data\"][\"data_config\"],\n",
    "            # loss_fn=run_config[\"loss_fn\"],\n",
    "            n_iters=120,\n",
    "            n_tests=1,\n",
    "            consider_metric=\"loss\",\n",
    "            lrs_to_try=[0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 1.0, 1.5, 2.0],\n",
    "        )\n",
    "        print(f\"  > Best lr: {run_config['opter']['opter_config']['lr']}\")\n",
    "\n",
    "    print(\"  > Running...\")\n",
    "    runs[run_name][\"log\"], _, _ = do_fit(\n",
    "        opter_cls=run_config[\"opter\"][\"opter_cls\"],\n",
    "        opter_config=run_config[\"opter\"][\"opter_config\"],\n",
    "        optee_cls=run_config[\"optee\"][\"optee_cls\"],\n",
    "        optee_config=run_config[\"optee\"][\"optee_config\"],\n",
    "        data_cls=run_config[\"data\"][\"data_cls\"],\n",
    "        data_config=run_config[\"data\"][\"data_config\"],\n",
    "        n_iters=run_config[\"n_iters\"],\n",
    "        l2o_dict=run_config[\"l2o_dict\"],\n",
    "        in_meta_training=False,\n",
    "        additional_metrics=run_config[\"additional_metrics\"],\n",
    "    )\n",
    "    runs[run_name][\"config\"] = run_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log(\n",
    "    runs,\n",
    "    only_metrics=[\"loss\", \"l2_dist(x*, x)\", \"time\"],\n",
    "    log_metrics=[\"loss\", \"l2_dist(x_tik*, x)\", \"l2_dist(x*, x)\"],\n",
    "    conv_win=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
